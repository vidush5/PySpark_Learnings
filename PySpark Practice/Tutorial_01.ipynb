{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24afd308-99ca-4a07-a7d6-5769342c1ed8",
   "metadata": {},
   "source": [
    "### 01. Union and UnionByName Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "683642fd-c4c5-4a93-b270-8824be73db78",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4cfdd7c-6ca5-41b9-aa60-03fd1fe22f92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80626764-49a3-4611-8997-fcaf28b42f22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"PySpark_Practice_01\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8dd18f13-fade-4905-8eea-bda326d4138d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "americans = spark.createDataFrame(\n",
    "    [(\"bab\", 42), (\"lisa\", 59)], [\"first_name\", \"age\"])\n",
    "\n",
    "colombians = spark.createDataFrame(\n",
    "    [(\"maria\", 20), (\"camilo\", 31)], [\"first_name\", \"age\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eed291af-224f-4e9f-b434-a306057882e1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---+\n",
      "|first_name|age|\n",
      "+----------+---+\n",
      "|       bab| 42|\n",
      "|      lisa| 59|\n",
      "|     maria| 20|\n",
      "|    camilo| 31|\n",
      "+----------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "res = americans.union(colombians)\n",
    "res.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c903f63-28f5-4afc-83cf-9f1abea2370d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------------+\n",
      "|Student Name|Overall Percentage|\n",
      "+------------+------------------+\n",
      "|       Nitya|             82.98|\n",
      "|    Abhishek|             80.31|\n",
      "+------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_frame1 = spark.createDataFrame(\n",
    "                [(\"Nitya\", 82.98), (\"Abhishek\", 80.31)],\n",
    "                [\"Student Name\", \"Overall Percentage\"]\n",
    ")\n",
    "\n",
    "data_frame1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab18ebed-f50b-44ff-8cd1-5212ba48bcf8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------------+\n",
      "|Overall Percentage|Student Name|\n",
      "+------------------+------------+\n",
      "|            91.123|      Naveen|\n",
      "|             90.51|     Sandeep|\n",
      "|             87.67|      Rakesh|\n",
      "+------------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_frame2 = spark.createDataFrame(\n",
    "                [(91.123, \"Naveen\"), (90.51, \"Sandeep\"), (87.67, \"Rakesh\")],\n",
    "                [\"Overall Percentage\", \"Student Name\"]\n",
    ")\n",
    "\n",
    "data_frame2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "908cdce3-2a49-4ff9-abac-3b823e7b526c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------------+\n",
      "|Student Name|Overall Percentage|\n",
      "+------------+------------------+\n",
      "|       Nitya|             82.98|\n",
      "|    Abhishek|             80.31|\n",
      "|      Naveen|            91.123|\n",
      "|     Sandeep|             90.51|\n",
      "|      Rakesh|             87.67|\n",
      "+------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "byName = data_frame1.unionByName(data_frame2)\n",
    "byName.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fde8cdd5-0f9d-4490-83a2-d0ff4f6540d5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------------+--------------------+\n",
      "|Student Name|Overall Percentage|          Department|\n",
      "+------------+------------------+--------------------+\n",
      "|   Bhuwanesh|             82.98|    Computer Science|\n",
      "|     Harshit|             80.31|Information Techn...|\n",
      "+------------+------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_frame3 = spark.createDataFrame(\n",
    "            [(\"Bhuwanesh\", 82.98, \"Computer Science\"), (\"Harshit\", 80.31, \"Information Technology\")],\n",
    "            [\"Student Name\", \"Overall Percentage\", \"Department\"]\n",
    ")\n",
    "\n",
    "data_frame3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed545434-ddab-4fea-a199-b721c5f0ab0c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------------+\n",
      "|Student Name|Overall Percentage|\n",
      "+------------+------------------+\n",
      "|      Naveen|            91.123|\n",
      "|      Piyush|             90.51|\n",
      "+------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_frame4 = spark.createDataFrame( \n",
    "    [(\"Naveen\", 91.123), (\"Piyush\", 90.51)], \n",
    "    [\"Student Name\", \"Overall Percentage\"] )\n",
    "\n",
    "data_frame4.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2247de33-b621-40c4-b83b-68bc8e8129d7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------------+--------------------+\n",
      "|Student Name|Overall Percentage|          Department|\n",
      "+------------+------------------+--------------------+\n",
      "|   Bhuwanesh|             82.98|    Computer Science|\n",
      "|     Harshit|             80.31|Information Techn...|\n",
      "|      Naveen|            91.123|                NULL|\n",
      "|      Piyush|             90.51|                NULL|\n",
      "+------------+------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "merged_df = data_frame3.unionByName(data_frame4, allowMissingColumns=True)\n",
    "merged_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2826e2e5-5f49-40fe-ad79-eca96621cc22",
   "metadata": {},
   "source": [
    "### 02. PySpark Window Ranking Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9d5ab231-8c28-462a-a651-513c4a4d6615",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.window import Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3d8a785f-1885-4123-9a0b-f0d5f09a88c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = ((\"Nitya\", 28, \"Sales\", 3000),\n",
    "        (\"Abhishek\", 33, \"Sales\", 4600),\n",
    "        (\"Sandeep\", 40, \"Sales\", 4100),\n",
    "        (\"Rakesh\", 25, \"Finance\", 3000),\n",
    "        (\"Ram\", 28, \"Sales\", 3000),\n",
    "        (\"Srishti\", 46, \"Management\", 3300),\n",
    "        (\"Arbind\", 26, \"Finance\", 3900),\n",
    "        (\"Hitesh\", 30, \"Marketing\", 3000),\n",
    "        (\"Kailash\", 29, \"Marketing\", 2000),\n",
    "        (\"Sushma\", 39, \"Sales\", 4100)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4e8c7367-b09c-4038-a58c-2d7245139043",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "schema = [\"Employee_Name\", \"Age\",\"Department\", \"Salary\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0cd9f1ce-a363-43b3-bc66-6bd1af5b527e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---+----------+------+\n",
      "|Employee_Name|Age|Department|Salary|\n",
      "+-------------+---+----------+------+\n",
      "|        Nitya| 28|     Sales|  3000|\n",
      "|     Abhishek| 33|     Sales|  4600|\n",
      "|      Sandeep| 40|     Sales|  4100|\n",
      "|       Rakesh| 25|   Finance|  3000|\n",
      "|          Ram| 28|     Sales|  3000|\n",
      "|      Srishti| 46|Management|  3300|\n",
      "|       Arbind| 26|   Finance|  3900|\n",
      "|       Hitesh| 30| Marketing|  3000|\n",
      "|      Kailash| 29| Marketing|  2000|\n",
      "|       Sushma| 39|     Sales|  4100|\n",
      "+-------------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.createDataFrame(data, schema)\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4abadd54-bd91-487e-aecf-63ac37135060",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "windowPartition = Window.partitionBy(\"Department\").orderBy(\"Age\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e70f460e-f030-43b1-89c3-81382802fa10",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Employee_Name: string (nullable = true)\n",
      " |-- Age: long (nullable = true)\n",
      " |-- Department: string (nullable = true)\n",
      " |-- Salary: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b689a15b-377a-4c4d-a90e-e0f0570d2eba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import cume_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "634bb13a-5517-4cd0-9ba6-cae8e4df6bee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---+----------+------+---------+\n",
      "|Employee_Name|Age|Department|Salary|cume_dist|\n",
      "+-------------+---+----------+------+---------+\n",
      "|       Rakesh| 25|   Finance|  3000|      0.5|\n",
      "|       Arbind| 26|   Finance|  3900|      1.0|\n",
      "|      Srishti| 46|Management|  3300|      1.0|\n",
      "|      Kailash| 29| Marketing|  2000|      0.5|\n",
      "|       Hitesh| 30| Marketing|  3000|      1.0|\n",
      "|        Nitya| 28|     Sales|  3000|      0.4|\n",
      "|          Ram| 28|     Sales|  3000|      0.4|\n",
      "|     Abhishek| 33|     Sales|  4600|      0.6|\n",
      "|       Sushma| 39|     Sales|  4100|      0.8|\n",
      "|      Sandeep| 40|     Sales|  4100|      1.0|\n",
      "+-------------+---+----------+------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn(\"cume_dist\", cume_dist().over(windowPartition)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9631bc4d-45c2-432e-95b5-abec00565577",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import lag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7dcefc6f-21a0-48d3-944c-4e83f254ae66",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---+----------+------+----+\n",
      "|Employee_Name|Age|Department|Salary| Lag|\n",
      "+-------------+---+----------+------+----+\n",
      "|       Rakesh| 25|   Finance|  3000|NULL|\n",
      "|       Arbind| 26|   Finance|  3900|NULL|\n",
      "|      Srishti| 46|Management|  3300|NULL|\n",
      "|      Kailash| 29| Marketing|  2000|NULL|\n",
      "|       Hitesh| 30| Marketing|  3000|NULL|\n",
      "|        Nitya| 28|     Sales|  3000|NULL|\n",
      "|          Ram| 28|     Sales|  3000|NULL|\n",
      "|     Abhishek| 33|     Sales|  4600|3000|\n",
      "|       Sushma| 39|     Sales|  4100|3000|\n",
      "|      Sandeep| 40|     Sales|  4100|4600|\n",
      "+-------------+---+----------+------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn(\"Lag\", lag(\"Salary\", 2).over(windowPartition)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8a71d5cb-c786-4875-9ac5-5329fa2a2132",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import lead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a49ed103-5ca1-48cb-98ca-24a1ca0748b9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---+----------+------+----+\n",
      "|Employee_Name|Age|Department|Salary|Lead|\n",
      "+-------------+---+----------+------+----+\n",
      "|       Rakesh| 25|   Finance|  3000|NULL|\n",
      "|       Arbind| 26|   Finance|  3900|NULL|\n",
      "|      Srishti| 46|Management|  3300|NULL|\n",
      "|      Kailash| 29| Marketing|  2000|NULL|\n",
      "|       Hitesh| 30| Marketing|  3000|NULL|\n",
      "|        Nitya| 28|     Sales|  3000|4600|\n",
      "|          Ram| 28|     Sales|  3000|4100|\n",
      "|     Abhishek| 33|     Sales|  4600|4100|\n",
      "|       Sushma| 39|     Sales|  4100|NULL|\n",
      "|      Sandeep| 40|     Sales|  4100|NULL|\n",
      "+-------------+---+----------+------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn(\"Lead\", lead(\"Salary\", 2).over(windowPartition)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a2f7d7-2d6c-448c-9b7c-c286b4328664",
   "metadata": {},
   "source": [
    "### 03. rank(), row_number(), dense_rank()  Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "511a134e-60ee-489d-b214-38df11a2e8b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sampleData = ((101, \"Ram\", \"Biology\", 80),\n",
    "                (103, \"Sita\", \"Social Science\", 78),\n",
    "                (104, \"Lakshman\", \"Sanskrit\", 58),\n",
    "                (102, \"Kunal\", \"Phisycs\", 89),\n",
    "                (101, \"Ram\", \"Biology\", 80),\n",
    "                (106, \"Srishti\", \"Maths\", 70),\n",
    "                (108, \"Sandeep\", \"Physics\", 75),\n",
    "                (107, \"Hitesh\", \"Maths\", 88),\n",
    "                (109, \"Kailash\", \"Maths\", 90),\n",
    "                (105, \"Abhishek\", \"Social Science\", 84)\n",
    "                )\n",
    "\n",
    "columns = [\"Roll_No\", \"Student_Name\", \"Subject\", \"Marks\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d8622322-fa63-4f16-85dc-05e1a42b3c51",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------+--------------+-----+\n",
      "|Roll_No|Student_Name|       Subject|Marks|\n",
      "+-------+------------+--------------+-----+\n",
      "|    101|         Ram|       Biology|   80|\n",
      "|    103|        Sita|Social Science|   78|\n",
      "|    104|    Lakshman|      Sanskrit|   58|\n",
      "|    102|       Kunal|       Phisycs|   89|\n",
      "|    101|         Ram|       Biology|   80|\n",
      "|    106|     Srishti|         Maths|   70|\n",
      "|    108|     Sandeep|       Physics|   75|\n",
      "|    107|      Hitesh|         Maths|   88|\n",
      "|    109|     Kailash|         Maths|   90|\n",
      "|    105|    Abhishek|Social Science|   84|\n",
      "+-------+------------+--------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2 = spark.createDataFrame(sampleData, columns)\n",
    "\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "00e6beaa-96e7-4750-a51c-3b4ba249448c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "windowPartition2 = Window.partitionBy(\"Subject\").orderBy(\"Marks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ffc465ff-1db0-40ca-b55e-37626eae7d6f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Roll_No: long (nullable = true)\n",
      " |-- Student_Name: string (nullable = true)\n",
      " |-- Subject: string (nullable = true)\n",
      " |-- Marks: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2c4d57ba-3acc-42c2-b3d0-bec125873f93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import row_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dd2a07bd-3c9c-4b11-afee-61b0e1bb47d0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------+--------------+-----+----------+\n",
      "|Roll_No|Student_Name|       Subject|Marks|row_number|\n",
      "+-------+------------+--------------+-----+----------+\n",
      "|    101|         Ram|       Biology|   80|         1|\n",
      "|    101|         Ram|       Biology|   80|         2|\n",
      "|    106|     Srishti|         Maths|   70|         1|\n",
      "|    107|      Hitesh|         Maths|   88|         2|\n",
      "|    109|     Kailash|         Maths|   90|         3|\n",
      "|    102|       Kunal|       Phisycs|   89|         1|\n",
      "|    108|     Sandeep|       Physics|   75|         1|\n",
      "|    104|    Lakshman|      Sanskrit|   58|         1|\n",
      "|    103|        Sita|Social Science|   78|         1|\n",
      "|    105|    Abhishek|Social Science|   84|         2|\n",
      "+-------+------------+--------------+-----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.withColumn(\"row_number\", row_number().over(windowPartition2)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6516bbe0-06af-4a57-a41d-0e3bfdd6c86c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------+--------------+-----+----+\n",
      "|Roll_No|Student_Name|       Subject|Marks|rank|\n",
      "+-------+------------+--------------+-----+----+\n",
      "|    101|         Ram|       Biology|   80|   1|\n",
      "|    101|         Ram|       Biology|   80|   1|\n",
      "|    106|     Srishti|         Maths|   70|   1|\n",
      "|    107|      Hitesh|         Maths|   88|   2|\n",
      "|    109|     Kailash|         Maths|   90|   3|\n",
      "|    102|       Kunal|       Phisycs|   89|   1|\n",
      "|    108|     Sandeep|       Physics|   75|   1|\n",
      "|    104|    Lakshman|      Sanskrit|   58|   1|\n",
      "|    103|        Sita|Social Science|   78|   1|\n",
      "|    105|    Abhishek|Social Science|   84|   2|\n",
      "+-------+------------+--------------+-----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import rank\n",
    "df2.withColumn(\"rank\", rank().over(windowPartition2)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9380fd8d-20e7-478c-8f1b-13ce536acd0e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------+--------------+-----+----+\n",
      "|Roll_No|Student_Name|       Subject|Marks|rank|\n",
      "+-------+------------+--------------+-----+----+\n",
      "|    101|         Ram|       Biology|   80|   1|\n",
      "|    101|         Ram|       Biology|   80|   1|\n",
      "|    106|     Srishti|         Maths|   70|   1|\n",
      "|    107|      Hitesh|         Maths|   88|   2|\n",
      "|    109|     Kailash|         Maths|   90|   3|\n",
      "|    102|       Kunal|       Phisycs|   89|   1|\n",
      "|    108|     Sandeep|       Physics|   75|   1|\n",
      "|    104|    Lakshman|      Sanskrit|   58|   1|\n",
      "|    103|        Sita|Social Science|   78|   1|\n",
      "|    105|    Abhishek|Social Science|   84|   2|\n",
      "+-------+------------+--------------+-----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import dense_rank\n",
    "df2.withColumn(\"rank\", dense_rank().over(windowPartition2)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb220c98-e9bd-4554-8695-7858446a8a8c",
   "metadata": {},
   "source": [
    "### 04. Aggregate Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "62bbaa68-0d22-446a-9555-295308170520",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "emp_data = ((\"Ram\", \"Sales\", 3000),\n",
    "            (\"Meena\", \"Sales\", 4600),\n",
    "            (\"Abhishek\", \"Sales\", 4100),\n",
    "            (\"Kunal\", \"Finance\", 3000),\n",
    "            (\"Ram\", \"Sales\", 3000),\n",
    "            (\"Srishti\", \"Management\", 3300),\n",
    "            (\"Sandeep\", \"Finance\", 3900),\n",
    "            (\"Hitesh\", \"Marketing\", 3000),\n",
    "            (\"Kailash\", \"Marketing\", 2000),\n",
    "            (\"Shyam\", \"Sales\", 4100)\n",
    "            )\n",
    "\n",
    "col = [\"Employee_name\", \"Department\", \"Salary\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "039f4fd9-ea90-456c-b703-f2a870af74f1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+------+\n",
      "|Employee_name|Department|Salary|\n",
      "+-------------+----------+------+\n",
      "|          Ram|     Sales|  3000|\n",
      "|        Meena|     Sales|  4600|\n",
      "|     Abhishek|     Sales|  4100|\n",
      "|        Kunal|   Finance|  3000|\n",
      "|          Ram|     Sales|  3000|\n",
      "|      Srishti|Management|  3300|\n",
      "|      Sandeep|   Finance|  3900|\n",
      "|       Hitesh| Marketing|  3000|\n",
      "|      Kailash| Marketing|  2000|\n",
      "|        Shyam|     Sales|  4100|\n",
      "+-------------+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3 = spark.createDataFrame(emp_data, col)\n",
    "df3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c102857c-32d8-4dcd-9b3b-37737dfc3222",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Employee_name: string (nullable = true)\n",
      " |-- Department: string (nullable = true)\n",
      " |-- Salary: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7532f132-af4f-4a45-b18d-dd045418baac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import col, avg, sum, min, max, row_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e74e8256-b991-43aa-8c54-93779382ae02",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "windowPartitionAgg = Window.partitionBy(\"Department\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7951c36b-9b66-4d2b-94b6-8380eae1274e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+------+------+\n",
      "|Employee_name|Department|Salary|   Avg|\n",
      "+-------------+----------+------+------+\n",
      "|        Kunal|   Finance|  3000|3450.0|\n",
      "|      Sandeep|   Finance|  3900|3450.0|\n",
      "|      Srishti|Management|  3300|3300.0|\n",
      "|       Hitesh| Marketing|  3000|2500.0|\n",
      "|      Kailash| Marketing|  2000|2500.0|\n",
      "|          Ram|     Sales|  3000|3760.0|\n",
      "|        Meena|     Sales|  4600|3760.0|\n",
      "|     Abhishek|     Sales|  4100|3760.0|\n",
      "|          Ram|     Sales|  3000|3760.0|\n",
      "|        Shyam|     Sales|  4100|3760.0|\n",
      "+-------------+----------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3.withColumn(\"Avg\", avg(col(\"salary\")).over(windowPartitionAgg)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "120f17a5-613a-49be-b202-3a99d2be2192",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+------+-----+\n",
      "|Employee_name|Department|Salary|  Sum|\n",
      "+-------------+----------+------+-----+\n",
      "|        Kunal|   Finance|  3000| 6900|\n",
      "|      Sandeep|   Finance|  3900| 6900|\n",
      "|      Srishti|Management|  3300| 3300|\n",
      "|       Hitesh| Marketing|  3000| 5000|\n",
      "|      Kailash| Marketing|  2000| 5000|\n",
      "|          Ram|     Sales|  3000|18800|\n",
      "|        Meena|     Sales|  4600|18800|\n",
      "|     Abhishek|     Sales|  4100|18800|\n",
      "|          Ram|     Sales|  3000|18800|\n",
      "|        Shyam|     Sales|  4100|18800|\n",
      "+-------------+----------+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3.withColumn(\"Sum\", sum(col(\"salary\")).over(windowPartitionAgg)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c181f493-28a7-41f2-9a94-d24d1ee28854",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+------+----+\n",
      "|Employee_name|Department|Salary| Min|\n",
      "+-------------+----------+------+----+\n",
      "|        Kunal|   Finance|  3000|3000|\n",
      "|      Sandeep|   Finance|  3900|3000|\n",
      "|      Srishti|Management|  3300|3300|\n",
      "|       Hitesh| Marketing|  3000|2000|\n",
      "|      Kailash| Marketing|  2000|2000|\n",
      "|          Ram|     Sales|  3000|3000|\n",
      "|        Meena|     Sales|  4600|3000|\n",
      "|     Abhishek|     Sales|  4100|3000|\n",
      "|          Ram|     Sales|  3000|3000|\n",
      "|        Shyam|     Sales|  4100|3000|\n",
      "+-------------+----------+------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3.withColumn(\"Min\", min(col(\"salary\")).over(windowPartitionAgg)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c08c4372-ad34-40c1-9765-6578c477e116",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+------+----+\n",
      "|Employee_name|Department|Salary| Max|\n",
      "+-------------+----------+------+----+\n",
      "|        Kunal|   Finance|  3000|3900|\n",
      "|      Sandeep|   Finance|  3900|3900|\n",
      "|      Srishti|Management|  3300|3300|\n",
      "|       Hitesh| Marketing|  3000|3000|\n",
      "|      Kailash| Marketing|  2000|3000|\n",
      "|          Ram|     Sales|  3000|4600|\n",
      "|        Meena|     Sales|  4600|4600|\n",
      "|     Abhishek|     Sales|  4100|4600|\n",
      "|          Ram|     Sales|  3000|4600|\n",
      "|        Shyam|     Sales|  4100|4600|\n",
      "+-------------+----------+------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3.withColumn(\"Max\", max(col(\"salary\")).over(windowPartitionAgg)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa944d9-15d4-43f1-bf1a-321b01db6a52",
   "metadata": {},
   "source": [
    "### 05. date and timestamp functions in timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9e207b-3b4b-4e33-ba4d-0f5d9f08de04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
